import pandas as pd
from typing import Optional, List, Dict, Tuple

class JiraPhaseDurationTracker:
    def __init__(
        self,
        csv_path: str,
        phase_definitions: Dict[str, Tuple[List[str], List[str]]]
    ):
        # 1) Read raw CSV
        self.df = pd.read_csv(csv_path)
        self.phases = phase_definitions
        self._prepare()

    def _prepare(self):
        # normalize column names
        self.df.columns = self.df.columns.str.strip()

        # --- 2) Handle your Created timestamp as a status change ---
        if 'created' in self.df.columns:
            created_df = self.df[['Jira_Id', 'created']].rename(columns={'created': 'Timestamp'})
            created_df['Change_Item']  = 'status'
            created_df['Change_Value'] = 'Created'
            # bring requirement_detail & epic_link along
            for c in ('requirement_detail','epic_link'):
                if c in self.df.columns:
                    created_df[c] = self.df[c]
            # subset to only the cols we care about
            cols = ['Jira_Id','Timestamp','Change_Item','Change_Value']
            if 'requirement_detail' in created_df: cols.append('requirement_detail')
            if 'epic_link'        in created_df: cols.append('epic_link')
            created_df = created_df[cols]
            # append
            self.df = pd.concat([self.df, created_df], ignore_index=True)

        # --- 3) Parse timestamps & filter to status changes ---
        self.df['Timestamp'] = pd.to_datetime(self.df['Timestamp'], errors='coerce')
        self.df = self.df.sort_values(['Jira_Id','Timestamp'], ignore_index=True)
        self.df = self.df[self.df['Change_Item'].str.lower() == 'status']

    def _calculate_raw_total_time(self, g: pd.DataFrame) -> Optional[float]:
        times = g['Timestamp'].dropna()
        if len(times) < 2:
            return None
        span = times.max() - times.min()
        days = span.total_seconds() / 86400
        return round(days, 2) if days > 0 else None

    def calculate_all_phases(self) -> pd.DataFrame:
        output = []

        for jira_id, group in self.df.groupby('Jira_Id', sort=False):
            g = group.sort_values('Timestamp', ignore_index=True)

            # capture requirement_detail & epic_link
            req_id = g['requirement_detail'].iloc[0] if 'requirement_detail' in g.columns else None
            epic   = g['epic_link'].iloc[0]        if 'epic_link'        in g.columns else None

            # 1) compute each phase by pairwise Δ-time
            durations = {phase: 0.0 for phase in self.phases}
            rows = list(g.itertuples(index=False))
            for prev, curr in zip(rows, rows[1:]):
                dt_days = (curr.Timestamp - prev.Timestamp).total_seconds() / 86400
                pst = prev.Change_Value.strip()
                cst = curr.Change_Value.strip()
                for phase, (starts, ends) in self.phases.items():
                    if pst in starts and cst in ends:
                        durations[phase] += dt_days
                        break

            # 2) find time-to-first-update
            created_ts = g.loc[g.Change_Value=='Created','Timestamp']
            first_change_ts = g.loc[g.Change_Value!='Created','Timestamp']
            if not created_ts.empty and not first_change_ts.empty:
                delta = (first_change_ts.min() - created_ts.min()).total_seconds() / 86400
                time_to_first = round(delta, 2) if delta>0 else 0.0
            else:
                time_to_first = None

            # 3) raw span
            raw = self._calculate_raw_total_time(g)

            # 4) build row
            row = {
                'Jira_Id': jira_id,
                'Requirement_Id': req_id,
                'Epic': epic,
                'Time to First Update (days)': time_to_first,
                'Raw Total Time (days)': raw
            }

            tracked = 0.0
            for phase, total in durations.items():
                val = round(total, 2) if total>0 else None
                row[f"{phase} (days)"] = val
                if val is not None:
                    tracked += val

            row['Total Time (days)'] = round(tracked, 2) if tracked>0 else None
            row['Gap Time (days)']   = (
                round(raw - tracked, 2)
                if raw is not None and tracked>0
                else None
            )

            output.append(row)

        return pd.DataFrame(output)


if __name__ == "__main__":
    # --- your singleton‐list phase definitions here ---
    phase_definitions = {
        "Design Time":      (["Design in progress"],    ["Design Complete"]),
        "Build Queue":      (["Design Complete"],       ["Build in progress"]),
        "Build Time":       (["Build in progress"],     ["Build Complete"]),
        "Block Time":       (["Closed","Reopened"],     ["To Test"]),
        "FT Queue":         (["To Test"],               ["Blocked / On Hold","Ready for FT"]),
        "FT Time":          (["FT IN PROGRESS"],        ["Blocked / On Hold","Ready for UAT"]),
        "UAT Queue Time":   (["Ready for UAT"],         ["UAT IN PROGRESS"]),
        "UAT Time":         (["UAT IN PROGRESS"],       ["Closed"]),
    }

    tracker = JiraPhaseDurationTracker("jira_logs.csv", phase_definitions)
    df = tracker.calculate_all_phases()

    # collapse Block/FT‐Queue/FT‐Time fragments if you still split them:
    # (example shown only for Block Time; repeat for other prefixes)
    # block_cols = [c for c in df if c.startswith("Block Time") and "(days)" in c]
    # df["Block Time (days)"] = df[block_cols].sum(axis=1); df.drop(columns=block_cols, inplace=True)

    df.to_excel("phase_durations_summary.xlsx", index=False)
    print("Done. phase_durations_summary.xlsx now includes Requirement_Id and Time to First Update.") 