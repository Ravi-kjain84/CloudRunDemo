import pandas as pd
from typing import Optional, List, Dict, Tuple

class JiraPhaseDurationTracker:
    def __init__(
        self,
        csv_path: str,
        phase_definitions: Dict[str, Tuple[List[str], List[str]]]
    ):
        # Keep raw for 'created' lookup
        self.raw_df = pd.read_csv(csv_path)
        # And a working copy for status changes
        self.df = self.raw_df.copy()
        self.phases = phase_definitions
        self._prepare()

    def _prepare(self):
        # parse timestamps
        self.df['Timestamp'] = pd.to_datetime(self.df['Timestamp'], errors='coerce')
        # keep only statusâ€‘change rows
        self.df = self.df[self.df['Change_Item'].str.lower() == 'status']
        # sort by Jira_Id then time
        self.df = self.df.sort_values(['Jira_Id','Timestamp'], ignore_index=True)

    def _calculate_raw_total_time(self, g: pd.DataFrame) -> Optional[float]:
        times = g['Timestamp'].dropna()
        if len(times) < 2:
            return None
        span = times.max() - times.min()
        days = span.total_seconds() / 86400
        return round(days, 2)

    def calculate_all_phases(self) -> pd.DataFrame:
        output_rows = []

        for jira_id, group in self.df.groupby('Jira_Id', sort=False):
            g = group.sort_values('Timestamp', ignore_index=True)

            # 1) Pull the 'created' timestamp from raw_df
            created_ts = None
            if 'created' in self.raw_df.columns:
                try:
                    created_raw = self.raw_df.loc[
                        self.raw_df['Jira_Id']==jira_id, 'created'
                    ].iloc[0]
                    created_ts = pd.to_datetime(created_raw, errors='coerce')
                except Exception:
                    created_ts = None

            # 2) Compute pairwise durations into each phase
            durations = {phase: 0.0 for phase in self.phases}
            rows = list(g.itertuples(index=False))
            for prev, curr in zip(rows, rows[1:]):
                delta = (curr.Timestamp - prev.Timestamp).total_seconds() / 86400
                prev_st = prev.Change_Value.strip()
                curr_st = curr.Change_Value.strip()
                for phase, (starts, ends) in self.phases.items():
                    if prev_st in starts and curr_st in ends:
                        durations[phase] += delta
                        break

            # 3) Build the output row
            row: Dict[str, Optional[float]] = {'Jira_Id': jira_id}

            # Requirement ID
            if 'requirement_detail' in self.raw_df.columns:
                reqs = self.raw_df.loc[
                    self.raw_df['Jira_Id']==jira_id, 'requirement_detail'
                ].unique()
                row['Requirement_Id'] = reqs[0] if len(reqs)>0 else None

            # Epic (optional)
            if 'epic_link' in self.raw_df.columns:
                epics = self.raw_df.loc[
                    self.raw_df['Jira_Id']==jira_id, 'epic_link'
                ].unique()
                row['Epic'] = epics[0] if len(epics)>0 else None

            # Time to First Update
            first_status_ts = g['Timestamp'].min() if not g.empty else None
            if created_ts is not None and first_status_ts is not None:
                delta_first = (first_status_ts - created_ts).total_seconds() / 86400
                row['Time to First Update (days)'] = round(delta_first, 2)
            else:
                row['Time to First Update (days)'] = None

            # 4) Round each phase, sum tracked
            tracked = 0.0
            for phase, total in durations.items():
                val = round(total, 2) if total > 0 else None
                row[f"{phase} (days)"] = val
                if val is not None:
                    tracked += val

            # Raw total & gap
            raw = self._calculate_raw_total_time(g)
            row['Raw Total Time (days)']   = raw
            row['Total Time (days)']       = round(tracked, 2) if tracked>0 else None
            row['Gap Time (days)']         = (
                round(raw - tracked, 2)
                if (raw is not None and tracked>0)
                else None
            )

            output_rows.append(row)

        return pd.DataFrame(output_rows)


if __name__ == "__main__":
    # --------------------
    # 1) Your phase definitions
    # --------------------
    phase_definitions = {
        "Design Time":    (["Design in progress"],    ["Design Complete"]),
        "Build Queue":    (["Design Complete"],       ["Build in progress"]),
        "Build Time":     (["Build in progress"],     ["Build Complete"]),
        "Block Time":     (["Closed","Reopened"],     ["To Test"]),
        "FT Queue":       (["To Test"],               ["Blocked / On Hold","Ready for FT"]),
        "FT Time":        (["FT IN PROGRESS"],        ["Blocked / On Hold","Ready for UAT"]),
        "UAT Queue Time": (["Ready for UAT"],         ["UAT IN PROGRESS"]),
        "UAT Time":       (["UAT IN PROGRESS"],       ["Closed"]),
    }

    # --------------------
    # 2) Run & collapse fragments
    # --------------------
    tracker = JiraPhaseDurationTracker("jira_logs.csv", phase_definitions)
    df = tracker.calculate_all_phases()

    # collapse just in case you need single columns:
    for prefix, out in [
        ("Block Time",    "Block Time (days)"),
        ("FT Queue",      "FT Queue Time (days)"),
        ("FT Time",       "FT Time (days)")
    ]:
        parts = [c for c in df.columns if c.startswith(prefix) and "(days)" in c]
        if parts:
            df[out] = df[parts].sum(axis=1)
            df.drop(columns=parts, inplace=True)

    # --------------------
    # 3) Export
    # --------------------
    df.to_excel("phase_durations_summary.xlsx", index=False)
    print("phase_durations_summary.xlsx generated with Time to First Update.") 